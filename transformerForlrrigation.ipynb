{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformerForlrrigation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voBXoa8wf2SZ",
        "outputId": "c220963b-88cd-46a9-e0a9-533a3e18b503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting icecream\n",
            "  Downloading icecream-2.1.1-py2.py3-none-any.whl (8.1 kB)\n",
            "Collecting executing>=0.3.1\n",
            "  Downloading executing-0.8.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting colorama>=0.3.9\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting asttokens>=2.0.1\n",
            "  Downloading asttokens-2.0.5-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n",
            "Installing collected packages: executing, colorama, asttokens, icecream\n",
            "Successfully installed asttokens-2.0.5 colorama-0.4.4 executing-0.8.2 icecream-2.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install icecream\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from joblib import dump\n",
        "from icecream import ic"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Data Loader***"
      ],
      "metadata": {
        "id": "aWDNtk5M113B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SensorDataset(Dataset):\n",
        "    \n",
        "\n",
        "    def __init__(self, csv_name, training_length, forecast_window):\n",
        "        \n",
        "        # load raw data file\n",
        "        csv_file = os.path.join(csv_name)\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        df = pd.read_csv(csv_file)\n",
        "        self.df.columns = df.columns.str.replace(' ', '')\n",
        "        self.transform = MinMaxScaler()\n",
        "        self.T = training_length\n",
        "        self.S = forecast_window\n",
        "\n",
        "    def __len__(self):\n",
        "        # return number of sensors\n",
        "        return len(self.df.groupby(by=[\"id\"]))\n",
        "\n",
        "    # Will pull an index between 0 and __len__. \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        # Sensors are indexed from 1\n",
        "        idx = idx+1\n",
        "\n",
        "\n",
        "        start = np.random.randint(0, len(self.df[self.df[\"id\"]==idx]) - self.T - self.S) \n",
        "        sensor_number = str(self.df[self.df[\"id\"]==idx][[\"sensor_id\"]][start:start+1].values.item())\n",
        "        index_in = torch.tensor([i for i in range(start, start+self.T)])\n",
        "        index_tar = torch.tensor([i for i in range(start + self.T, start + self.T + self.S)])\n",
        "        _input = torch.tensor(self.df[self.df[\"id\"]==idx][[\"station\",\"adv\", \"sin_second\", \"cos_second\", \"sin_minute\", \"cos_minute\"]][start : start + self.T].values)\n",
        "        target = torch.tensor(self.df[self.df[\"id\"]==idx][[\"station\",\"adv\", \"sin_second\", \"cos_second\", \"sin_minute\", \"cos_minute\"]][start + self.T : start + self.T + self.S].values)\n",
        "\n",
        "        # ---------------Infiltrated Depth-----------------#\n",
        "        # _input = torch.tensor(self.df[self.df[\"id\"]==idx][[\"station\",\"inf_depth\", \"sin_second\", \"cos_second\", \"sin_minute\", \"cos_minute\"]][start : start + self.T].values)\n",
        "        #target = torch.tensor(self.df[self.df[\"id\"]==idx][[\"station\",\"inf_depth\", \"sin_second\", \"cos_second\", \"sin_minute\", \"cos_minute\"]][start + self.T : start + self.T + self.S].values)\n",
        "\n",
        "\n",
        "        # scalar is fit only to the input\n",
        "        scaler = self.transform\n",
        "\n",
        "        scaler.fit(_input[:,0].unsqueeze(-1))\n",
        "        _input[:,0] = torch.tensor(scaler.transform(_input[:,0].unsqueeze(-1)).squeeze(-1))\n",
        "        target[:,0] = torch.tensor(scaler.transform(target[:,0].unsqueeze(-1)).squeeze(-1))\n",
        "\n",
        "        # save the scalar to be used later when inverse translating the data for plotting.\n",
        "        dump(scaler, 'scalar_item.joblib')\n",
        "\n",
        "        return index_in, index_tar, _input, target, sensor_number"
      ],
      "metadata": {
        "id": "r2ogGWzqf80k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***helpers***"
      ],
      "metadata": {
        "id": "b4kw6bVH2ds7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "\n",
        "# save train or validation loss\n",
        "def log_loss(loss_val : float, path_to_save_loss : str, train : bool = True):\n",
        "    if train:\n",
        "        file_name = \"train_loss.txt\"\n",
        "    else:\n",
        "        file_name = \"val_loss.txt\"\n",
        "\n",
        "    path_to_file = path_to_save_loss+file_name\n",
        "    os.makedirs(os.path.dirname(path_to_file), exist_ok=True)\n",
        "    with open(path_to_file, \"a\") as f:\n",
        "        f.write(str(loss_val)+\"\\n\")\n",
        "        f.close()\n",
        "\n",
        "# Exponential Moving Average\n",
        "def EMA(values, alpha=0.1):\n",
        "    ema_values = [values[0]]\n",
        "    for idx, item in enumerate(values[1:]):\n",
        "        ema_values.append(alpha*item + (1-alpha)*ema_values[idx])\n",
        "    return ema_values\n",
        "\n",
        "# Remove all files from previous executions and re-run the model.\n",
        "def clean_directory():\n",
        "\n",
        "    if os.path.exists('save_loss'):\n",
        "        shutil.rmtree('save_loss')\n",
        "    if os.path.exists('save_model'): \n",
        "        shutil.rmtree('save_model')\n",
        "    if os.path.exists('save_predictions'): \n",
        "        shutil.rmtree('save_predictions')\n",
        "    os.mkdir(\"save_loss\")\n",
        "    os.mkdir(\"save_model\")\n",
        "    os.mkdir(\"save_predictions\")"
      ],
      "metadata": {
        "id": "o8uh8amWgHdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***model***"
      ],
      "metadata": {
        "id": "6phwWfYt2q7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch, math\n",
        "from icecream import ic\n",
        "import time\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    # d_model : number of features\n",
        "    def __init__(self,feature_size=6,num_layers=3,dropout=0):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=6, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
        "        self.decoder = nn.Linear(feature_size,1)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1    \n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def forward(self, src, device):\n",
        "        \n",
        "        mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
        "        output = self.transformer_encoder(src,mask)\n",
        "        output = self.decoder(output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "wD8lnlzmgKzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import logging\n",
        "import time # debugging\n",
        "from joblib import load\n",
        "from icecream import ic"
      ],
      "metadata": {
        "id": "IO9q6gzCgRTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***inference***"
      ],
      "metadata": {
        "id": "cuklnrRW25ET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(name)s %(message)s\", datefmt=\"[%H:%M:%S]\")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def inference(path_to_save_predictions, forecast_window, dataloader, device, path_to_save_model, best_model):\n",
        "\n",
        "    device = torch.device(device)\n",
        "    \n",
        "    model = Transformer().double().to(device)\n",
        "    model.load_state_dict(torch.load(path_to_save_model+best_model))\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        model.eval()\n",
        "        for plot in range(25):\n",
        "\n",
        "            for index_in, index_tar, _input, target, sensor_number in dataloader:\n",
        "                \n",
        "                # starting from 1 so that src matches with target, but has same length as when training\n",
        "                src = _input.permute(1,0,2).double().to(device)[1:, :, :] \n",
        "                target = target.permute(1,0,2).double().to(device) \n",
        "\n",
        "                next_input_model = src\n",
        "                all_predictions = []\n",
        "\n",
        "                for i in range(forecast_window - 1):\n",
        "                    \n",
        "                    prediction = model(next_input_model, device) \n",
        "\n",
        "                    if all_predictions == []:\n",
        "                        all_predictions = prediction \n",
        "                    else:\n",
        "                        all_predictions = torch.cat((all_predictions, prediction[-1,:,:].unsqueeze(0))) \n",
        "\n",
        "                    pos_encoding_old_vals = src[i+1:, :, 1:] \n",
        "                    pos_encoding_new_val = target[i + 1, :, 1:].unsqueeze(1) \n",
        "                    pos_encodings = torch.cat((pos_encoding_old_vals, pos_encoding_new_val)) \n",
        "                    \n",
        "                    next_input_model = torch.cat((src[i+1:, :, 0].unsqueeze(-1), prediction[-1,:,:].unsqueeze(0))) \n",
        "                    next_input_model = torch.cat((next_input_model, pos_encodings), dim = 2) \n",
        "\n",
        "                true = torch.cat((src[1:,:,0],target[:-1,:,0]))\n",
        "                loss = criterion(true, all_predictions[:,:,0])\n",
        "                val_loss += loss\n",
        "            \n",
        "            val_loss = val_loss/10\n",
        "            scaler = load('scalar_item.joblib')\n",
        "            src_adv = scaler.inverse_transform(src[:,:,0].cpu())\n",
        "            target_adv = scaler.inverse_transform(target[:,:,0].cpu())\n",
        "            prediction_adv = scaler.inverse_transform(all_predictions[:,:,0].detach().cpu().numpy())\n",
        "            plot_prediction(plot, path_to_save_predictions, src_adv, target_adv, prediction_adv, sensor_number, index_in, index_tar)\n",
        "\n",
        "        logger.info(f\"Loss On Unseen Dataset: {val_loss.item()}\")"
      ],
      "metadata": {
        "id": "P8UtKAwXgVtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***plot***"
      ],
      "metadata": {
        "id": "u4v1nfwn3GgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from icecream import ic \n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def plot_loss(path_to_save, train=True):\n",
        "    plt.rcParams.update({'font.size': 10})\n",
        "    with open(path_to_save + \"/train_loss.txt\", 'r') as f:\n",
        "        loss_list = [float(line) for line in f.readlines()]\n",
        "    if train:\n",
        "        title = \"Train\"\n",
        "    else:\n",
        "        title = \"Validation\"\n",
        "    EMA_loss = EMA(loss_list)\n",
        "    plt.plot(loss_list, label = \"loss\")\n",
        "    plt.plot(EMA_loss, label=\"EMA loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.title(title+\"_loss\")\n",
        "    plt.savefig(path_to_save+f\"/{title}.png\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_prediction(title, path_to_save, src, tgt, prediction, sensor_number, index_in, index_tar):\n",
        "\n",
        "    idx_scr = index_in[0, 1:].tolist()\n",
        "    idx_tgt = index_tar[0].tolist()\n",
        "    idx_pred = [i for i in range(idx_scr[0] +1, idx_tgt[-1])] \n",
        "\n",
        "    plt.figure(figsize=(15,6))\n",
        "    plt.rcParams.update({\"font.size\" : 16})\n",
        "\n",
        "    # plotting\n",
        "    plt.plot(idx_scr, src, '-', color = 'blue', label = 'Input', linewidth=2)\n",
        "    plt.plot(idx_tgt, tgt, '-', color = 'indigo', label = 'Target', linewidth=2)\n",
        "    plt.plot(idx_pred, prediction,'--', color = 'limegreen', label = 'Forecast', linewidth=2)\n",
        "\n",
        "    #formatting\n",
        "    plt.grid(b=True, which='major', linestyle = 'solid')\n",
        "    plt.minorticks_on()\n",
        "    plt.grid(b=True, which='minor', linestyle = 'dashed', alpha=0.5)\n",
        "    plt.xlabel(\"Time Elapsed\")\n",
        "    plt.ylabel(\"Adv (%)\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Forecast from Sensor \" + str(sensor_number[0]))\n",
        "\n",
        "    # save\n",
        "    plt.savefig(path_to_save+f\"Prediction_{title}.png\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_training(epoch, path_to_save, src, prediction, sensor_number, index_in, index_tar):\n",
        "\n",
        "\n",
        "    idx_scr = [i for i in range(len(src))]\n",
        "    idx_pred = [i for i in range(1, len(prediction)+1)]\n",
        "\n",
        "    plt.figure(figsize=(15,6))\n",
        "    plt.rcParams.update({\"font.size\" : 18})\n",
        "    plt.grid(b=True, which='major', linestyle = '-')\n",
        "    plt.grid(b=True, which='minor', linestyle = '--', alpha=0.5)\n",
        "    plt.minorticks_on()\n",
        "\n",
        "    plt.plot(idx_scr, src, 'o-.', color = 'blue', label = 'input sequence', linewidth=1)\n",
        "    plt.plot(idx_pred, prediction, 'o-.', color = 'limegreen', label = 'prediction sequence', linewidth=1)\n",
        "\n",
        "    plt.title(\"Teaching Forcing from Sensor \" + str(sensor_number[0]) + \", Epoch \" + str(epoch))\n",
        "    plt.xlabel(\"Time Elapsed\")\n",
        "    plt.ylabel(\"Adv (%)\")\n",
        "    plt.legend()\n",
        "    plt.savefig(path_to_save+f\"/Epoch_{str(epoch)}.png\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_training_3(epoch, path_to_save, src, sampled_src, prediction, sensor_number, index_in, index_tar):\n",
        "  \n",
        "\n",
        "    idx_scr = [i for i in range(len(src))]\n",
        "    idx_pred = [i for i in range(1, len(prediction)+1)]\n",
        "    idx_sampled_src = [i for i in range(len(sampled_src))]\n",
        "\n",
        "    plt.figure(figsize=(15,6))\n",
        "    plt.rcParams.update({\"font.size\" : 18})\n",
        "    plt.grid(b=True, which='major', linestyle = '-')\n",
        "    plt.grid(b=True, which='minor', linestyle = '--', alpha=0.5)\n",
        "    plt.minorticks_on()\n",
        "\n",
        "    ## REMOVE DROPOUT FOR THIS PLOT TO APPEAR AS EXPECTED !! DROPOUT INTERFERES WITH HOW THE SAMPLED SOURCES ARE PLOTTED\n",
        "    plt.plot(idx_sampled_src, sampled_src, 'o-.', color='red', label = 'sampled source', linewidth=1, markersize=10)\n",
        "    plt.plot(idx_scr, src, 'o-.', color = 'blue', label = 'input sequence', linewidth=1)\n",
        "    plt.plot(idx_pred, prediction, 'o-.', color = 'limegreen', label = 'prediction sequence', linewidth=1)\n",
        "    plt.title(\"Teaching Forcing from Sensor \" + str(sensor_number[0]) + \", Epoch \" + str(epoch))\n",
        "    plt.xlabel(\"Time Elapsed\")\n",
        "    plt.ylabel(\"Adv (%)\")\n",
        "    plt.legend()\n",
        "    plt.savefig(path_to_save+f\"/Epoch_{str(epoch)}.png\")\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "7HFqioY1gZrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Preprocessing***"
      ],
      "metadata": {
        "id": "JyMKAowp3L-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "import datetime\n",
        "from icecream import ic\n",
        "\n",
        "def process_data(source):\n",
        "\n",
        "    source = \"/content/drive/MyDrive/train_tf.csv\"\n",
        "    df = pd.read_csv(source)\n",
        "\n",
        "    df_new = df[df['time'].notnull()]\n",
        "    \n",
        "    \n",
        "    timestamps = [ts.split('+')[0] for ts in  df['time']]\n",
        "    \n",
        "    timestamps_second = np.array([float(datetime.datetime.strptime(t, '%H:%M:%S').second) for t in timestamps])\n",
        "    timestamps_minute = np.array([float(datetime.datetime.strptime(t, '%H:%M:%S').minute) for t in timestamps])\n",
        "    timestamps_hour = np.array([float(datetime.datetime.strptime(t, '%H:%M:%S').hour) for t in timestamps])\n",
        " \n",
        "    second_in_minute = 60\n",
        "    minute_in_hour = 60\n",
        "\n",
        "    df['sin_second'] = np.sin(2*np.pi*timestamps_second/second_in_minute)\n",
        "    df['cos_second'] = np.cos(2*np.pi*timestamps_second/second_in_minute)\n",
        "    df['sin_minute'] = np.sin(2*np.pi*timestamps_minute/minute_in_hour)\n",
        "    df['cos_minute'] = np.cos(2*np.pi*timestamps_minute/minute_in_hour)\n",
        "\n",
        "    return df\n",
        "\n",
        "train_dataset = process_data('/content/drive/MyDrive/train_tf.csv')\n",
        "test_dataset = process_data('/content/drive/MyDrive/test_tf.csv')\n",
        "\n",
        "train_dataset.to_csv(r'/content/drive/MyDrive/train_dataset.csv', index=False)\n",
        "test_dataset.to_csv(r'/content/drive/MyDrive/test_dataset.csv', index=False)\n"
      ],
      "metadata": {
        "id": "F6KnJBPrgfFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import logging\n",
        "import time # debugging\n",
        "from joblib import load\n",
        "from icecream import ic\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "PtYNBRaQgqJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***train_teacher_forcing***"
      ],
      "metadata": {
        "id": "Per-yJEH3WXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN8Z_shs-6Qf",
        "outputId": "3ff65418-b521-4047-94fb-f8fc84e7c841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(name)s %(message)s\", datefmt=\"[%H:%M:%S]\")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def transformer(dataloader, EPOCH, frequency, path_to_save_model, path_to_save_loss, path_to_save_predictions, device):\n",
        "\n",
        "    device = torch.device(device)\n",
        "\n",
        "    model = Transformer().double().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    criterion = torch.nn.MSELoss()\n",
        "    best_model = \"\"\n",
        "    min_train_loss = float('inf')\n",
        "\n",
        "    for epoch in range(EPOCH + 1):\n",
        "\n",
        "        train_loss = 0\n",
        "        val_loss = 0\n",
        "\n",
        "        ## TRAIN -- TEACHER FORCING\n",
        "        model.train()\n",
        "        for index_in, index_tar, _input, target, sensor_number in dataloader: # for each data set \n",
        "        \n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            src = _input.permute(1,0,2).double().to(device)[:-1,:,:] \n",
        "            target = _input.permute(1,0,2).double().to(device)[1:,:,:] \n",
        "            prediction = model(src, device) \n",
        "            loss = criterion(prediction, target[:,:,0].unsqueeze(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.detach().item()\n",
        "\n",
        "        if train_loss < min_train_loss:\n",
        "            torch.save(model.state_dict(), path_to_save_model + f\"best_train_{epoch}.pth\")\n",
        "            torch.save(optimizer.state_dict(), path_to_save_model + f\"optimizer_{epoch}.pth\")\n",
        "            min_train_loss = train_loss\n",
        "            best_model = f\"best_train_{epoch}.pth\"\n",
        "\n",
        "\n",
        "        if epoch % 100 == 0: # Plot 1-Step Predictions\n",
        "\n",
        "            logger.info(f\"Epoch: {epoch}, Training loss: {train_loss}\")\n",
        "            scaler = load('scalar_item.joblib')\n",
        "            src_adv = scaler.inverse_transform(src[:,:,0].cpu()) \n",
        "            target_adv = scaler.inverse_transform(target[:,:,0].cpu()) \n",
        "            prediction_adv = scaler.inverse_transform(prediction[:,:,0].detach().cpu().numpy()) \n",
        "            plot_training(epoch, path_to_save_predictions, src_adv, prediction_adv, sensor_number, index_in, index_tar)\n",
        "\n",
        "        train_loss /= len(dataloader)\n",
        "        log_loss(train_loss, path_to_save_loss, train=True)\n",
        "        \n",
        "    plot_loss(path_to_save_loss, train=True)\n",
        "    return best_model"
      ],
      "metadata": {
        "id": "07Nl1m7UgwHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import logging\n",
        "import time # debugging\n",
        "from joblib import load\n",
        "from icecream import ic\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import math, random"
      ],
      "metadata": {
        "id": "IAOovfSXrrPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***train_with_sampling***"
      ],
      "metadata": {
        "id": "2YhV2rNB4Z6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(name)s %(message)s\", datefmt=\"[%H:%M:%S]\")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def flip_from_probability(p):\n",
        "    return True if random.random() < p else False\n",
        "\n",
        "def transformer(dataloader, EPOCH, k, frequency, path_to_save_model, path_to_save_loss, path_to_save_predictions, device):\n",
        "\n",
        "    device = torch.device(device)\n",
        "\n",
        "    model = Transformer().double().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    \n",
        "    criterion = torch.nn.MSELoss()\n",
        "    best_model = \"\"\n",
        "    min_train_loss = float('inf')\n",
        "\n",
        "    for epoch in range(EPOCH + 1):\n",
        "        train_loss = 0\n",
        "        val_loss = 0\n",
        "\n",
        "        ## TRAIN -- TEACHER FORCING\n",
        "        model.train()\n",
        "        for index_in, index_tar, _input, target, sensor_number in dataloader:\n",
        "        \n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            src = _input.permute(1,0,2).double().to(device)[:-1,:,:] \n",
        "            target = _input.permute(1,0,2).double().to(device)[1:,:,:] \n",
        "            sampled_src = src[:1, :, :] \n",
        "\n",
        "            for i in range(len(target)-1):\n",
        "\n",
        "                prediction = model(sampled_src, device) \n",
        "                \n",
        "\n",
        "                if i < 60: # One hour, enough data to make inferences about cycles\n",
        "                    prob_true_val = True\n",
        "                else:\n",
        "                    ## coin flip\n",
        "                    v = k/(k+math.exp(epoch/k)) # probability of heads/tails depends on the epoch, evolves with time.\n",
        "                    prob_true_val = flip_from_probability(v) # starts with over 95 % probability of true val for each flip in epoch 0.\n",
        "                    ## if using true value as new value\n",
        "\n",
        "                if prob_true_val: # Using true value as next value\n",
        "                    sampled_src = torch.cat((sampled_src.detach(), src[i+1, :, :].unsqueeze(0).detach()))\n",
        "                else: ## using prediction as new value\n",
        "                    positional_encodings_new_val = src[i+1,:,1:].unsqueeze(0)\n",
        "                    predicted_adv = torch.cat((prediction[-1,:,:].unsqueeze(0), positional_encodings_new_val), dim=2)\n",
        "                    sampled_src = torch.cat((sampled_src.detach(), predicted_adv.detach()))\n",
        "            \n",
        "            \"\"\"To update model after each sequence\"\"\"\n",
        "            loss = criterion(target[:-1,:,0].unsqueeze(-1), prediction)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.detach().item()\n",
        "\n",
        "        if train_loss < min_train_loss:\n",
        "            torch.save(model.state_dict(), path_to_save_model + f\"best_train_{epoch}.pth\")\n",
        "            torch.save(optimizer.state_dict(), path_to_save_model + f\"optimizer_{epoch}.pth\")\n",
        "            min_train_loss = train_loss\n",
        "            best_model = f\"best_train_{epoch}.pth\"\n",
        "\n",
        "\n",
        "        if epoch % 10 == 0: # Plot 1-Step Predictions\n",
        "\n",
        "            logger.info(f\"Epoch: {epoch}, Training loss: {train_loss}\")\n",
        "            scaler = load('scalar_item.joblib')\n",
        "            sampled_src_adv = scaler.inverse_transform(sampled_src[:,:,0].cpu()) \n",
        "            src_adv = scaler.inverse_transform(src[:,:,0].cpu()) \n",
        "            target_adv = scaler.inverse_transform(target[:,:,0].cpu()) \n",
        "            prediction_adv = scaler.inverse_transform(prediction[:,:,0].detach().cpu().numpy()) \n",
        "            plot_training_3(epoch, path_to_save_predictions, src_adv, sampled_src_adv, prediction_adv, sensor_number, index_in, index_tar)\n",
        "\n",
        "        train_loss /= len(dataloader)\n",
        "        log_loss(train_loss, path_to_save_loss, train=True)\n",
        "        \n",
        "    plot_loss(path_to_save_loss, train=True)\n",
        "    return best_model"
      ],
      "metadata": {
        "id": "qhiNs60Aruub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch"
      ],
      "metadata": {
        "id": "lMAxT2VD80Ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***main***"
      ],
      "metadata": {
        "id": "6nK2a9OK4geD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def main(\n",
        "    epoch: int = 100,\n",
        "    k: int = 60,\n",
        "    batch_size: int = 1,\n",
        "    frequency: int = 100,\n",
        "    training_length = 20,\n",
        "    forecast_window = 10,\n",
        "    train_csv = \"/content/drive/MyDrive/train_dataset.csv\",\n",
        "    test_csv = \"/content/drive/MyDrive/test_dataset.csv\",\n",
        "    path_to_save_model = \"save_model/\",\n",
        "    path_to_save_loss = \"save_loss/\", \n",
        "    path_to_save_predictions = \"save_predictions/\", \n",
        "    device = \"cpu\"\n",
        "):\n",
        "\n",
        "    clean_directory()\n",
        "\n",
        "    train_dataset = SensorDataset(csv_name = train_csv, training_length = training_length, forecast_window = forecast_window)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "    test_dataset = SensorDataset(csv_name = test_csv, training_length = training_length, forecast_window = forecast_window)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "    best_model = transformer(train_dataloader, epoch, k, frequency, path_to_save_model, path_to_save_loss, path_to_save_predictions, device)\n",
        "    inference(path_to_save_predictions, forecast_window, test_dataloader, device, path_to_save_model, best_model)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--epoch\", type=int, default=1000)\n",
        "    parser.add_argument(\"--k\", type=int, default=60)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=1)\n",
        "    parser.add_argument(\"--frequency\", type=int, default=100)\n",
        "    parser.add_argument(\"--path_to_save_model\",type=str,default=\"save_model/\")\n",
        "    parser.add_argument(\"--path_to_save_loss\",type=str,default=\"save_loss/\")\n",
        "    parser.add_argument(\"--path_to_save_predictions\",type=str,default=\"save_predictions/\")\n",
        "    parser.add_argument(\"--device\", type=str, default=\"cpu\")\n",
        "    parser.add_argument('-f')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    main(\n",
        "        epoch=args.epoch,\n",
        "        k = args.k,\n",
        "        batch_size=args.batch_size,\n",
        "        frequency=args.frequency,\n",
        "        path_to_save_model=args.path_to_save_model,\n",
        "        path_to_save_loss=args.path_to_save_loss,\n",
        "        path_to_save_predictions=args.path_to_save_predictions,\n",
        "        device=args.device,\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk1_LBRY814v",
        "outputId": "218eda51-2ba3-4c58-f918-f34b08b2066b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[16:15:03] [INFO] numexpr.utils NumExpr defaulting to 2 threads.\n",
            "[16:15:03] [INFO] __main__ Epoch: 0, Training loss: 1.532418952139624\n",
            "[16:15:06] [INFO] __main__ Epoch: 10, Training loss: 0.343826187792709\n",
            "[16:15:08] [INFO] __main__ Epoch: 20, Training loss: 0.2900434066778815\n",
            "[16:15:10] [INFO] __main__ Epoch: 30, Training loss: 0.2787524962637764\n",
            "[16:15:12] [INFO] __main__ Epoch: 40, Training loss: 0.20757770208568357\n",
            "[16:15:15] [INFO] __main__ Epoch: 50, Training loss: 0.19424026324049043\n",
            "[16:15:17] [INFO] __main__ Epoch: 60, Training loss: 0.1516767547851013\n",
            "[16:15:19] [INFO] __main__ Epoch: 70, Training loss: 0.1348850622758433\n",
            "[16:15:21] [INFO] __main__ Epoch: 80, Training loss: 0.2685659794453261\n",
            "[16:15:23] [INFO] __main__ Epoch: 90, Training loss: 0.15355413853275304\n",
            "[16:15:26] [INFO] __main__ Epoch: 100, Training loss: 0.15213427433682508\n",
            "[16:15:28] [INFO] __main__ Epoch: 110, Training loss: 0.16579302747608865\n",
            "[16:15:30] [INFO] __main__ Epoch: 120, Training loss: 0.11186755597442287\n",
            "[16:15:32] [INFO] __main__ Epoch: 130, Training loss: 0.11231268202700735\n",
            "[16:15:34] [INFO] __main__ Epoch: 140, Training loss: 0.06263136879145742\n",
            "[16:15:37] [INFO] __main__ Epoch: 150, Training loss: 0.07151376098003852\n",
            "[16:15:39] [INFO] __main__ Epoch: 160, Training loss: 0.06021714436959947\n",
            "[16:15:41] [INFO] __main__ Epoch: 170, Training loss: 0.0930271795145393\n",
            "[16:15:43] [INFO] __main__ Epoch: 180, Training loss: 0.08905040131635775\n",
            "[16:15:45] [INFO] __main__ Epoch: 190, Training loss: 0.13602366495792545\n",
            "[16:15:47] [INFO] __main__ Epoch: 200, Training loss: 0.061577657616215344\n",
            "[16:15:50] [INFO] __main__ Epoch: 210, Training loss: 0.09611661837062405\n",
            "[16:15:52] [INFO] __main__ Epoch: 220, Training loss: 0.16006049470884712\n",
            "[16:15:54] [INFO] __main__ Epoch: 230, Training loss: 0.14291438540841306\n",
            "[16:15:56] [INFO] __main__ Epoch: 240, Training loss: 0.07111428917515612\n",
            "[16:15:58] [INFO] __main__ Epoch: 250, Training loss: 0.07117111860422443\n",
            "[16:16:00] [INFO] __main__ Epoch: 260, Training loss: 0.09062078898188518\n",
            "[16:16:03] [INFO] __main__ Epoch: 270, Training loss: 0.05198597816880874\n",
            "[16:16:05] [INFO] __main__ Epoch: 280, Training loss: 0.07111844458907246\n",
            "[16:16:07] [INFO] __main__ Epoch: 290, Training loss: 0.0688997390363876\n",
            "[16:16:09] [INFO] __main__ Epoch: 300, Training loss: 0.06835205489206037\n",
            "[16:16:11] [INFO] __main__ Epoch: 310, Training loss: 0.05542940428774411\n",
            "[16:16:13] [INFO] __main__ Epoch: 320, Training loss: 0.14861285453912398\n",
            "[16:16:15] [INFO] __main__ Epoch: 330, Training loss: 0.09339579206768168\n",
            "[16:16:18] [INFO] __main__ Epoch: 340, Training loss: 0.08882779952996225\n",
            "[16:16:20] [INFO] __main__ Epoch: 350, Training loss: 0.09559998179630996\n",
            "[16:16:22] [INFO] __main__ Epoch: 360, Training loss: 0.04625560063498933\n",
            "[16:16:24] [INFO] __main__ Epoch: 370, Training loss: 0.053793960934326125\n",
            "[16:16:26] [INFO] __main__ Epoch: 380, Training loss: 0.09289628630559603\n",
            "[16:16:29] [INFO] __main__ Epoch: 390, Training loss: 0.049025643440292255\n",
            "[16:16:31] [INFO] __main__ Epoch: 400, Training loss: 0.08871771109842855\n",
            "[16:16:33] [INFO] __main__ Epoch: 410, Training loss: 0.09015101361392822\n",
            "[16:16:35] [INFO] __main__ Epoch: 420, Training loss: 0.042934002614034183\n",
            "[16:16:37] [INFO] __main__ Epoch: 430, Training loss: 0.04774477569847558\n",
            "[16:16:40] [INFO] __main__ Epoch: 440, Training loss: 0.0472179339376091\n",
            "[16:16:42] [INFO] __main__ Epoch: 450, Training loss: 0.023142844637233952\n",
            "[16:16:44] [INFO] __main__ Epoch: 460, Training loss: 0.04188605585461702\n",
            "[16:16:46] [INFO] __main__ Epoch: 470, Training loss: 0.031103375779046663\n",
            "[16:16:48] [INFO] __main__ Epoch: 480, Training loss: 0.05835435673022984\n",
            "[16:16:50] [INFO] __main__ Epoch: 490, Training loss: 0.025034731264867754\n",
            "[16:16:53] [INFO] __main__ Epoch: 500, Training loss: 0.05031252859432438\n",
            "[16:16:55] [INFO] __main__ Epoch: 510, Training loss: 0.048953496011319556\n",
            "[16:16:57] [INFO] __main__ Epoch: 520, Training loss: 0.10219477719888724\n",
            "[16:16:59] [INFO] __main__ Epoch: 530, Training loss: 0.034842666666601366\n",
            "[16:17:01] [INFO] __main__ Epoch: 540, Training loss: 0.01799866691767225\n",
            "[16:17:04] [INFO] __main__ Epoch: 550, Training loss: 0.03997266352427562\n",
            "[16:17:06] [INFO] __main__ Epoch: 560, Training loss: 0.016953540786797373\n",
            "[16:17:08] [INFO] __main__ Epoch: 570, Training loss: 0.11702175667336615\n",
            "[16:17:10] [INFO] __main__ Epoch: 580, Training loss: 0.03242044663053595\n",
            "[16:17:12] [INFO] __main__ Epoch: 590, Training loss: 0.0162128682183689\n",
            "[16:17:15] [INFO] __main__ Epoch: 600, Training loss: 0.032088035018327514\n",
            "[16:17:17] [INFO] __main__ Epoch: 610, Training loss: 0.03538151141209759\n",
            "[16:17:19] [INFO] __main__ Epoch: 620, Training loss: 0.044988592164066005\n",
            "[16:17:21] [INFO] __main__ Epoch: 630, Training loss: 0.03961456724433751\n",
            "[16:17:23] [INFO] __main__ Epoch: 640, Training loss: 0.027952294128101334\n",
            "[16:17:26] [INFO] __main__ Epoch: 650, Training loss: 0.05063825917186017\n",
            "[16:17:28] [INFO] __main__ Epoch: 660, Training loss: 0.059824630852956286\n",
            "[16:17:30] [INFO] __main__ Epoch: 670, Training loss: 0.037113342452990174\n",
            "[16:17:32] [INFO] __main__ Epoch: 680, Training loss: 0.050711492204158395\n",
            "[16:17:34] [INFO] __main__ Epoch: 690, Training loss: 0.04751554391361187\n",
            "[16:17:37] [INFO] __main__ Epoch: 700, Training loss: 0.09103785574722359\n",
            "[16:17:39] [INFO] __main__ Epoch: 710, Training loss: 0.03189145989171446\n",
            "[16:17:41] [INFO] __main__ Epoch: 720, Training loss: 0.026262024559167978\n",
            "[16:17:43] [INFO] __main__ Epoch: 730, Training loss: 0.03540163930689894\n",
            "[16:17:45] [INFO] __main__ Epoch: 740, Training loss: 0.027860523652082733\n",
            "[16:17:48] [INFO] __main__ Epoch: 750, Training loss: 0.019029097952726316\n",
            "[16:17:50] [INFO] __main__ Epoch: 760, Training loss: 0.011282155277549465\n",
            "[16:17:52] [INFO] __main__ Epoch: 770, Training loss: 0.01672246449438948\n",
            "[16:17:54] [INFO] __main__ Epoch: 780, Training loss: 0.015497241310155669\n",
            "[16:17:56] [INFO] __main__ Epoch: 790, Training loss: 0.026906846809719158\n",
            "[16:17:58] [INFO] __main__ Epoch: 800, Training loss: 0.04409343809328693\n",
            "[16:18:00] [INFO] __main__ Epoch: 810, Training loss: 0.03522256103769346\n",
            "[16:18:03] [INFO] __main__ Epoch: 820, Training loss: 0.035372653440363354\n",
            "[16:18:05] [INFO] __main__ Epoch: 830, Training loss: 0.02003737508927876\n",
            "[16:18:07] [INFO] __main__ Epoch: 840, Training loss: 0.06914046604328451\n",
            "[16:18:09] [INFO] __main__ Epoch: 850, Training loss: 0.053784233300142856\n",
            "[16:18:11] [INFO] __main__ Epoch: 860, Training loss: 0.02291706574183524\n",
            "[16:18:14] [INFO] __main__ Epoch: 870, Training loss: 0.022091375217050655\n",
            "[16:18:16] [INFO] __main__ Epoch: 880, Training loss: 0.02220858431866938\n",
            "[16:18:18] [INFO] __main__ Epoch: 890, Training loss: 0.04158194035499938\n",
            "[16:18:20] [INFO] __main__ Epoch: 900, Training loss: 0.04289863685515235\n",
            "[16:18:23] [INFO] __main__ Epoch: 910, Training loss: 0.0257391301205315\n",
            "[16:18:25] [INFO] __main__ Epoch: 920, Training loss: 0.020183190386474918\n",
            "[16:18:27] [INFO] __main__ Epoch: 930, Training loss: 0.03152243887045939\n",
            "[16:18:29] [INFO] __main__ Epoch: 940, Training loss: 0.04577479117837112\n",
            "[16:18:31] [INFO] __main__ Epoch: 950, Training loss: 0.07287571804531548\n",
            "[16:18:33] [INFO] __main__ Epoch: 960, Training loss: 0.011145307874102253\n",
            "[16:18:36] [INFO] __main__ Epoch: 970, Training loss: 0.025810103701765667\n",
            "[16:18:38] [INFO] __main__ Epoch: 980, Training loss: 0.015808641763858197\n",
            "[16:18:40] [INFO] __main__ Epoch: 990, Training loss: 0.019103715410993604\n",
            "[16:18:42] [INFO] __main__ Epoch: 1000, Training loss: 0.014728752890465236\n",
            "[16:18:53] [INFO] __main__ Loss On Unseen Dataset: 0.027164266760744953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pdSwuoNY9xb1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}